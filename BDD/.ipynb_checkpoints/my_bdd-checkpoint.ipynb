{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation of the DB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect (\"./gtfs_tag/gtfs_tag.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'Sample Agency',\n",
       " 'http://www.sampleagency.com',\n",
       " 'GMT',\n",
       " 'en',\n",
       " '123-456-7890',\n",
       " 'http://www.samplefare.com',\n",
       " 'sample@email.com')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = cur.execute(\"SELECT * FROM agency\")\n",
    "res.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entering data into the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data into the Agency table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    INSERT INTO \"Agency\" (\n",
    "        \"agency_name\",\n",
    "        \"agency_url\",\n",
    "        \"agency_timezone\",\n",
    "        \"agency_lang\",\n",
    "        \"agency_phone\",\n",
    "        \"agency_fare_url\",\n",
    "        \"agency_email\"\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "''', ('Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com'))\n",
    "\n",
    "# Commit the changes to the database\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(2, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(3, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(4, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(5, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(6, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(7, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n",
      "(8, 'Sample Agency', 'http://www.sampleagency.com', 'GMT', 'en', '123-456-7890', 'http://www.samplefare.com', 'sample@email.com')\n"
     ]
    }
   ],
   "source": [
    "# Execute a SELECT query to retrieve data from the 'Agency' table\n",
    "cur.execute('SELECT * FROM \"Agency\"')\n",
    "\n",
    "# Fetch all the rows from the query result\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Display the retrieved data\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data into the Stops table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    INSERT INTO \"stops\" (\n",
    "        \"stop_code\",\n",
    "        \"stop_name\",\n",
    "        \"stop_desc\",\n",
    "        \"stop_lat\",\n",
    "        \"stop_lon\",\n",
    "        \"zone_id\",\n",
    "        \"stop_url\",\n",
    "        \"location_type\",\n",
    "        \"parent_station\",\n",
    "        \"stop_timezone\",\n",
    "        \"wheelchair_boarding\",\n",
    "        \"level_id\",\n",
    "        \"platform_code\"\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "''', ('S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A'))\n",
    "\n",
    "# Commit the changes to the database\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame with different data\n",
    "data = {\n",
    "    \"stop_code\": ['S002', 'S003', 'S004'],\n",
    "    \"stop_name\": ['New Stop', 'Another Stop', 'Yet Another Stop'],\n",
    "    \"stop_desc\": ['Description of the new stop', 'Description of another stop', 'Description of yet another stop'],\n",
    "    \"stop_lat\": ['35.6895', '40.7488', '34.0522'],\n",
    "    \"stop_lon\": ['139.6917', '-73.9857', '-118.2437'],\n",
    "    \"zone_id\": [2, 3, 4],\n",
    "    \"stop_url\": ['http://www.newstop.com', 'http://www.anotherstop.com', 'http://www.yetanotherstop.com'],\n",
    "    \"location_type\": ['Station', 'Station', 'Station'],\n",
    "    \"parent_station\": [0, 0, 0],\n",
    "    \"stop_timezone\": ['JST', 'EST', 'PST'],\n",
    "    \"wheelchair_boarding\": ['Yes', 'Yes', 'Yes'],\n",
    "    \"level_id\": [2, 3, 4],\n",
    "    \"platform_code\": ['B', 'C', 'D']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use Pandas to insert the DataFrame into the 'stops' table\n",
    "df.to_sql('stops', con, index=False, if_exists='append')\n",
    "\n",
    "# Commit the changes to the database\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(2, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(3, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(4, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(5, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(6, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(7, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(8, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(9, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(10, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(11, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(12, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(13, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(14, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(15, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(16, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(17, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(18, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(19, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(20, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(21, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(22, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(23, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(24, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(25, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(26, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(27, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(28, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(29, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(30, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(31, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(32, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(33, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n",
      "(34, 'S001', 'Sample Stop', 'Sample description', '40.7128', '-74.0060', 1, 'http://www.samplestop.com', 'Station', 0, 'GMT', 'Yes', 1, 'A')\n",
      "(35, 'S002', 'New Stop', 'Description of the new stop', '35.6895', '139.6917', 2, 'http://www.newstop.com', 'Station', 0, 'JST', 'Yes', 2, 'B')\n",
      "(36, 'S003', 'Another Stop', 'Description of another stop', '40.7488', '-73.9857', 3, 'http://www.anotherstop.com', 'Station', 0, 'EST', 'Yes', 3, 'C')\n",
      "(37, 'S004', 'Yet Another Stop', 'Description of yet another stop', '34.0522', '-118.2437', 4, 'http://www.yetanotherstop.com', 'Station', 0, 'PST', 'Yes', 4, 'D')\n"
     ]
    }
   ],
   "source": [
    "# Execute a SELECT query to retrieve data from the 'stops' table\n",
    "cur.execute('SELECT * FROM \"stops\"')\n",
    "\n",
    "# Fetch all the rows from the query result\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Display the retrieved data\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data from the Tag website and creation of the DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  route_id   trip_id                       trip_headsign  \\\n",
      "0        B  28181405                    Grenoble, Oxford   \n",
      "1       20  27743870             Veurey-Voroize, La Rive   \n",
      "2        B  28232978                    Grenoble, Oxford   \n",
      "3        7  27973488  Gières, Universités - IUT - UFRAPS   \n",
      "4        6  27785252  Saint-Martin-d'Hères, Henri Wallon   \n",
      "\n",
      "                                          service_id  direction_id  shape_id  \\\n",
      "0                        12345-MGHLV10_ST0_10_HI2324             1   SEM_B_2   \n",
      "1                        12345-MSILV00_ST21_0_HI2324             1  SEM_20_2   \n",
      "2  12345-MGHLV12_ST0_12_HI2324-MGHLV13_ST0_13_HI2324             1   SEM_B_2   \n",
      "3                        12345-MSILV00_ST21_0_HI2324             0  SEM_C7_1   \n",
      "4  1234567-MSHSAH05_ST5_5_HI2324-MSHSAH06_ST5_6_H...             1  SEM_C6_1   \n",
      "\n",
      "   wheelchair_accessible  bikes_allowed  \n",
      "0                      1              2  \n",
      "1                      1              2  \n",
      "2                      1              2  \n",
      "3                      1              2  \n",
      "4                      1              2  \n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "# Specify the path to the GTFS zip file\n",
    "gtfs_zip_path = 'SEM-GTFS.zip'\n",
    "\n",
    "# Specify the file within the zip archive you want to read (e.g., 'trips.txt')\n",
    "file_within_zip = 'trips.txt'\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(gtfs_zip_path, 'r') as zip_ref:\n",
    "    # Extract the specified file from the zip archive\n",
    "    with zip_ref.open(file_within_zip) as file:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df_trips = pd.read_csv(file)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_trips.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing stoptimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    trip_id  stop_id arrival_time departure_time  stop_sequence  pickup_type\n",
      "0  27647213     1297     12:31:00       12:31:00              1            0\n",
      "1  27647213     1296     12:32:00       12:32:00              2            0\n",
      "2  27647213     1294     12:34:00       12:34:00              3            0\n",
      "3  27647213     1293     12:35:00       12:35:00              4            0\n",
      "4  27647213     1548     12:36:00       12:36:00              5            0\n"
     ]
    }
   ],
   "source": [
    "# Specify the file within the zip archive you want to read (e.g., 'stop_times.txt')\n",
    "file_within_zip = 'stop_times.txt'\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(gtfs_zip_path, 'r') as zip_ref:\n",
    "    # Extract the specified file from the zip archive\n",
    "    with zip_ref.open(file_within_zip) as file_stop_times:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df_stop_times = pd.read_csv(file_stop_times)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_stop_times.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering the data from the DF in to the BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>service_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>wheelchair_accessible</th>\n",
       "      <th>bikes_allowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>28181405</td>\n",
       "      <td>Grenoble, Oxford</td>\n",
       "      <td>12345-MGHLV10_ST0_10_HI2324</td>\n",
       "      <td>1</td>\n",
       "      <td>SEM_B_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>27743870</td>\n",
       "      <td>Veurey-Voroize, La Rive</td>\n",
       "      <td>12345-MSILV00_ST21_0_HI2324</td>\n",
       "      <td>1</td>\n",
       "      <td>SEM_20_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>28232978</td>\n",
       "      <td>Grenoble, Oxford</td>\n",
       "      <td>12345-MGHLV12_ST0_12_HI2324-MGHLV13_ST0_13_HI2324</td>\n",
       "      <td>1</td>\n",
       "      <td>SEM_B_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>27973488</td>\n",
       "      <td>Gières, Universités - IUT - UFRAPS</td>\n",
       "      <td>12345-MSILV00_ST21_0_HI2324</td>\n",
       "      <td>0</td>\n",
       "      <td>SEM_C7_1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27785252</td>\n",
       "      <td>Saint-Martin-d'Hères, Henri Wallon</td>\n",
       "      <td>1234567-MSHSAH05_ST5_5_HI2324-MSHSAH06_ST5_6_H...</td>\n",
       "      <td>1</td>\n",
       "      <td>SEM_C6_1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>14</td>\n",
       "      <td>28009100</td>\n",
       "      <td>Grenoble, Verdun - Préfecture</td>\n",
       "      <td>12345-MAHLV00_ST0_0_HI2324</td>\n",
       "      <td>0</td>\n",
       "      <td>SEM_14_5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>1</td>\n",
       "      <td>27772235</td>\n",
       "      <td>Montbonnot-Saint-Martin, Pré de l'Eau</td>\n",
       "      <td>12345-MSHLVH02_ST8_2_HI2324-MSHLVH03_ST8_3_HI2...</td>\n",
       "      <td>0</td>\n",
       "      <td>SEM_C1_6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>A</td>\n",
       "      <td>28214871</td>\n",
       "      <td>Le Pont-de-Claix, L'Etoile</td>\n",
       "      <td>1234567-MEHS03_ST5_3_HI2324</td>\n",
       "      <td>0</td>\n",
       "      <td>SEM_A_3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>15</td>\n",
       "      <td>28216881</td>\n",
       "      <td>Grenoble, Verdun - Préfecture</td>\n",
       "      <td>1234567-MAHD02_ST6_2_HI2324</td>\n",
       "      <td>1</td>\n",
       "      <td>SEM_15_10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>E</td>\n",
       "      <td>28171418</td>\n",
       "      <td>Fontanil-Cornillon, Palluel</td>\n",
       "      <td>12345-MGHLV14_ST0_14_HI2324</td>\n",
       "      <td>1</td>\n",
       "      <td>SEM_E_1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21598 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      route_id   trip_id                          trip_headsign  \\\n",
       "0            B  28181405                       Grenoble, Oxford   \n",
       "1           20  27743870                Veurey-Voroize, La Rive   \n",
       "2            B  28232978                       Grenoble, Oxford   \n",
       "3            7  27973488     Gières, Universités - IUT - UFRAPS   \n",
       "4            6  27785252     Saint-Martin-d'Hères, Henri Wallon   \n",
       "...        ...       ...                                    ...   \n",
       "21593       14  28009100          Grenoble, Verdun - Préfecture   \n",
       "21594        1  27772235  Montbonnot-Saint-Martin, Pré de l'Eau   \n",
       "21595        A  28214871             Le Pont-de-Claix, L'Etoile   \n",
       "21596       15  28216881          Grenoble, Verdun - Préfecture   \n",
       "21597        E  28171418            Fontanil-Cornillon, Palluel   \n",
       "\n",
       "                                              service_id  direction_id  \\\n",
       "0                            12345-MGHLV10_ST0_10_HI2324             1   \n",
       "1                            12345-MSILV00_ST21_0_HI2324             1   \n",
       "2      12345-MGHLV12_ST0_12_HI2324-MGHLV13_ST0_13_HI2324             1   \n",
       "3                            12345-MSILV00_ST21_0_HI2324             0   \n",
       "4      1234567-MSHSAH05_ST5_5_HI2324-MSHSAH06_ST5_6_H...             1   \n",
       "...                                                  ...           ...   \n",
       "21593                         12345-MAHLV00_ST0_0_HI2324             0   \n",
       "21594  12345-MSHLVH02_ST8_2_HI2324-MSHLVH03_ST8_3_HI2...             0   \n",
       "21595                        1234567-MEHS03_ST5_3_HI2324             0   \n",
       "21596                        1234567-MAHD02_ST6_2_HI2324             1   \n",
       "21597                        12345-MGHLV14_ST0_14_HI2324             1   \n",
       "\n",
       "        shape_id  wheelchair_accessible  bikes_allowed  \n",
       "0        SEM_B_2                      1              2  \n",
       "1       SEM_20_2                      1              2  \n",
       "2        SEM_B_2                      1              2  \n",
       "3       SEM_C7_1                      1              2  \n",
       "4       SEM_C6_1                      1              2  \n",
       "...          ...                    ...            ...  \n",
       "21593   SEM_14_5                      1              2  \n",
       "21594   SEM_C1_6                      1              2  \n",
       "21595    SEM_A_3                      1              2  \n",
       "21596  SEM_15_10                      1              2  \n",
       "21597    SEM_E_1                      1              2  \n",
       "\n",
       "[21598 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shahaf.hen@Digital-Grenoble.local/cood/notebooks_all_modules/BDD'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21598"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trips.to_sql('Trips', con, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499438"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stop_times.to_sql('stop_times', con, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The functions to enter data into BDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this function creates the following string:\n",
    "    \"INSERT INTO trips VALUES (value1, value2, ..., valuen)\"\n",
    "    inputs :    table_name = a string\n",
    "                a_dict = a dict like {attribut1:value1, attribut2:value2, ... attributn : valuen}\n",
    "                whith attribut=variable from the db table and the txt file\n",
    "    \"\"\"\n",
    "def create_an_query(table_name:str, a_dict:dict):\n",
    "    a_tuple=tuple(list(a_dict.values()))\n",
    "    return f\"INSERT INTO {table_name} VALUES {a_tuple};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"INSERT INTO shahaf VALUES ('value1', 'value2');\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if it works\n",
    "sampul_dict = {'attribut1':'value1', 'attribut2':'value2'}\n",
    "\n",
    "create_an_query('shahaf', sampul_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"this function use the previous one to get the following list of strings :\n",
    "    [\"INSERT INTO trips VALUES (value1, value2, ..., valuen)\",  =>values of the first item of the table\n",
    "     \"INSERT INTO trips VALUES (value1, value2, ..., valuen)\",  =>values of the second item of the table\n",
    "     \"INSERT INTO trips VALUES (value1, value2, ..., valuen)\"]  =>etc etc\n",
    "    inputs :    tablename = a string of the db table\n",
    "                df = a dataframe with the values to add to the db\n",
    "    \"\"\"\n",
    "def get_insert_queries(tablename:str, df: pd.DataFrame) -> list:\n",
    "   \n",
    "    #first step : transform the df rows into a list of dict (like a_dict in the previous function)\n",
    "    df_dict = [] \n",
    "    for index_row in range(len(df)) :\n",
    "        df_dict.append(df.iloc[index_row].to_dict())\n",
    "    #second step : create a list of queries with the list of a_dict\n",
    "    list_queries=[]\n",
    "    for index_dict in range(len(df_dict)):\n",
    "        list_queries.append(create_an_query(tablename, df_dict[index_dict]))\n",
    "    return list_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_insert_file(filename:str, tablename:str, df:pd.DataFrame):\n",
    "    \n",
    "    ligne0='BEGIN TRANSACTION;'\n",
    "    lignefin='COMMIT;'\n",
    "    \n",
    "    ligne1=f'''CREATE TABLE IF NOT EXISTS {tablename} (\n",
    "        route_id TEXT NOT NULL,             \n",
    "        trip_id TEXT NOT NULL, \n",
    "        service_id TEXT NOT NULL,\n",
    "        trip_headsign TEXT NULL,\n",
    "        direction_id TEXT,\n",
    "        shape_id TEXT NULL,\n",
    "        wheelchair_accessible TEXT NULL,\n",
    "        bikes_allowed TEXT NULL,\n",
    "\tCONSTRAINT \"trips_pkey\" PRIMARY KEY(\"trip_id\")\n",
    "    );'''\n",
    "    serie_lignes=get_insert_queries(tablename, df)\n",
    "    with open(filename, 'w') as f :\n",
    "        f.write(ligne0)\n",
    "        f.write(ligne1)\n",
    "        for index_serie in range(len(serie_lignes)):\n",
    "            f.write(serie_lignes[index_serie])\n",
    "        f.write(lignefin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the path to the data files and the db file\n",
    "pathdata = \"SEM-GTFS.zip\"\n",
    "pathdb = \"gtf_tag.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connexion to the db\n",
    "con = sqlite3.connect (\"./gtfs_tag/gtfs_tag.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEM-GTFS.zip'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile  # Import the ZipFile class\n",
    "# Assuming you have a DataFrame named df_trips_update and a database connection con\n",
    "with ZipFile(pathdata) as z:\n",
    "    with z.open(\"trips.txt\") as f:\n",
    "        df_trips_update = pd.read_csv(f).astype(str).iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with the values to add to the db /!\\ just keep the 10 first values to be faster\n",
    "df_trips_update = pd.read_csv(ZipFile(pathdata).open(\"trips.txt\")).astype(str).iloc[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f283b7c5340>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete of the temporary db table \"trips_test\" \n",
    "con.execute('DROP TABLE IF EXISTS trips_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creation of the temporary db table \"trips_test\" (test)\n",
    "con.execute('CREATE TABLE IF NOT EXISTS stoptimes_test (trip_id, stop_id, arrival_time, departure_time, stop_sequence, pickup_type)')\n",
    "\n",
    "#creation of a query (test)\n",
    "#get_insert_queries(\"stoptimes_test\", df_stops_update.iloc[0].to_dict()) #ça marche \n",
    "\n",
    "#creation of a list of queries (test)\n",
    "#get_insert_queries(\"stoptimes_test\", df_stops_update.iloc[0:5]) #ça marche\n",
    "\n",
    "# creation of the sql file \n",
    "gen_insert_file(\"insert_trips.sql\", \"trips_test\", df_trips_update) #ça marche\n",
    "\n",
    "#execution of the sql file in the db\n",
    "with open(\"insert_trips.sql\", 'r') as sql_file:\n",
    "    sql_script = sql_file.read()\n",
    "cursor = con.cursor()\n",
    "cursor.executescript(sql_script)\n",
    "\n",
    "\n",
    "#merge the temporary db table \"trips_test\" with the original table \"trips\"\n",
    "con.execute('''\n",
    "    INSERT INTO trips(route_id,trip_id,trip_headsign,service_id,direction_id,shape_id,wheelchair_accessible,bikes_allowed)\n",
    "    SELECT\n",
    "        trips_test.route_id,\n",
    "        trips_test.trip_id,\n",
    "        trips_test.trip_headsign,\n",
    "        trips_test.service_id,\n",
    "        trips_test.direction_id,\n",
    "        trips_test.shape_id,\n",
    "        trips_test.wheelchair_accessible,\n",
    "        trips_test.bikes_allowed\n",
    "    FROM\n",
    "        trips_test\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM trips WHERE trips.trip_id = trips_test.trip_id\n",
    "    )\n",
    "''')\n",
    "\n",
    "#delete the temporary db table\n",
    "# con.execute('DROP TABLE IF EXISTS trips_test')\n",
    "\n",
    "#save the changes to the db\n",
    "con.commit()\n",
    "\n",
    "#close the db\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: where: command not found\n"
     ]
    }
   ],
   "source": [
    "!where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
