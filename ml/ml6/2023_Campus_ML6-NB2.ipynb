{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2dd3c2c",
   "metadata": {},
   "source": [
    "# Time series prediction (Part 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "399da4c9",
   "metadata": {},
   "source": [
    "**NB objectives**\n",
    "- [ ] Get to use few prediction models\n",
    "- [ ] Understand what CV is for"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3445fd01",
   "metadata": {},
   "source": [
    "**Required librairies**\n",
    "- [ ] matplotlib\n",
    "- [ ] numpy\n",
    "- [ ] pandas\n",
    "- [ ] seaborn\n",
    "- [ ] pmdarima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "757cfb53",
   "metadata": {},
   "source": [
    "## Prediction models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b1b7050",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d83b6f2",
   "metadata": {},
   "source": [
    "#### Theory behind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b68a73e",
   "metadata": {},
   "source": [
    "Le modèle ARMA (AutoRegressive Moving Average) ou ARMA (autorégressifs et moyenne mobile) en français, est un modèle adapté au prédiction sur toute série temporelle dont la valeur $Y$ à l'instant $t$ peut s'expliquer par les valeurs précédentes et les perturbations (bruits) précédentes.\n",
    "\n",
    "Avant de préciser ce qu'est un jeu de donnée suivant le modèle ARIMA, précisons un jeu de donnée suivant les conditions :  \n",
    "\n",
    "- **Autoregressif** : le modèle prédit la variable $Y$ à l'instant $t$, notée $Y_t$, à partir des valeurs précédentes de $Y$ selon un modèle de regression linéaire, c'est à dire $Y_{t-1}, Y_{t-2}, ..., Y_0$. On note $p$ le nombre de composantes utilisées pour prédire $Y_t$, avec\n",
    "\n",
    "> $Y_t = \\sum_{i=1}^p \\varphi_i\\,Y_{t-i} + \\varepsilon_t + c$, avec $\\varepsilon_t$ une perturbation, et c une constante.\n",
    "\n",
    "- **Moyenne mobile**: un modèle où les données sont le résultat de la moyenne mobile d'ordre $q$. Il est possible d'exprimer la valeur $Y_t$ à l'aide de la perturbation à l'instant $t$ et ses valeurs précédentes :\n",
    "\n",
    "> $Y_t = \\mu + \\varepsilon_t + \\sum_{1}^{q}\\theta_q\\varepsilon_{t-q}$, avec $\\mu$ une constante.\n",
    "\n",
    "Tout jeu de données ARIMA est la combinaison des conditions *AR* et *MA*, c'est à dire qu'il est autoregressif et son bruit suit une moyenne mobile. Soit :\n",
    "\n",
    "> $Y_t =  c + \\sum_{i=1}^p \\varphi_i\\,Y_{t-i} + \\varepsilon_t + \\sum_{1}^{q}\\theta_q\\varepsilon_{t_q}$\n",
    "\n",
    "ou :\n",
    "\n",
    "> $Y_t - \\sum_{i=1}^p \\varphi_i Y_{t-i} = \\varepsilon_t + \\sum_{i=1}^q \\theta_i \\varepsilon_{t-i}$ avec $\\varepsilon_t$ l'erreur du modèle autoregressif à l'instant $t$.\n",
    "\n",
    "Le modèle est optimisé à l'aide de la méthode des moindres carrées.\n",
    "\n",
    "\n",
    "Un modèle ARMA est adapté à des jeux de données stationnaires, c'est à dire avec une moyenne et un écart type fixe au cours du temps. Il est rare que l'on observe de telles données. De nombreux jeux de données de séries temporelles présentent des tendances sur la moyenne ou encore des saisonnalités. Pour cela, il convient de stationnariser dans un premier temps le problème. On parle **d'intégration**. Un modèle **ARIMA** est dit :\n",
    "\n",
    "- **intégré** : lorsqu'on peut corriger le jeu de donnée en réalisant le modèle sur $Y'_t = Y_t - Y_{t-1}$ pour une correction d'ordre 1 (d=1) ou encore $Y''_t = Y_t - Y_{t-1} - Y_{t-2}$ pour une correction d'ordre 2 (d=2), etc...  On note $d$ l'ordre de *correction par intégration* permet de supprimer les tendances polynomiales d'ordre $d$, avec:\n",
    "    \n",
    "> $Ycorr_t = Y_t - \\sum_{1}^{d} Y_{t-d}$\n",
    "\n",
    "\n",
    "Les modèles ARIMA sont souvent notés : ARIMA(p, d, q), soit **ARIMA(2, 1, 1)** signifie :\n",
    "- un modèle autoregressif d'ordre 2,\n",
    "- sur des données intégrées 1 fois,\n",
    "- et avec une moyenne mobile d'ordre 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cda334a9",
   "metadata": {},
   "source": [
    "#### Bit of practice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4ff4ec",
   "metadata": {},
   "source": [
    "##### Discover and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages (to be implemented if required)\n",
    "from pandas import date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '1949-01-01'\n",
    "airline = load_airpassengers(as_series=True)\n",
    "\n",
    "#there's no datetimeindex from the bundled dataset. So let's add one.\n",
    "airline.index= date_range(START_DATE, periods=len(airline), freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7515022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Plot to assess: \n",
    "# - \"Données passagers\", \n",
    "# - \"Moyenne glissante\" et \n",
    "# - \"Deviation standard glissante\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1263b805",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "- Is this time serie stationary or not?\n",
    "- What is its tendancy?\n",
    "- What about heteroskedasticity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot2: same infos as previously but with date on x axis and Y(t)-Y(t-1) on y axis\n",
    "# Use airline.diff().values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91187805",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    " - What about the stationarity?\n",
    " - What about the variance and how to deal with it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2 with modification defined in your previous conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "828de0f9",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    " - What about mean and deviation? Stationarity?\n",
    " \n",
    "<span style=\"color:green\">Then, it should be possible to apply ARIMA on these transformed data, with order 1 integration: ARIMA(p,1,q)</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b32bd9b9",
   "metadata": {},
   "source": [
    "##### Train/Test split challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325d04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain why train/test split can be a challenge for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0583e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(data, split_date):\n",
    "    '''\n",
    "    Split time series into training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    data - pd.DataFrame - time series data.  Index expected as datatimeindex\n",
    "    split_date - the date on which to split the time series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (len=2) \n",
    "    0. pandas.DataFrame - training dataset\n",
    "    1. pandas.DataFrame - test dataset\n",
    "    '''\n",
    "    train = data.loc[data.index < split_date]\n",
    "    test = data.loc[data.index >= split_date]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold back the last twelve months as a TEST set\n",
    "train, test = ts_train_test_split(airline / airline.index.days_in_month, '1959-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db01f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not forget to change your data (log)\n",
    "train_adj_log = np.log(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba96c5de",
   "metadata": {},
   "source": [
    "Afin de valider les paramètres $p$ (*AR*) et $q$ (*MA*) du modèle ARIMA, l'on peut calculer l'auto-corrélation des données temporelles.\n",
    "- Pour déterminer $p$ nous utiliserons l'autocorrelation des données par une donnée passée avec un décalage temporel (appelé *lag* en anglais). On utilisera pour cela la PACF (*Partial Auto Correlation Function*). La fonction PACF cherche à déterminer la correlation entre les données $Y_t$ et $Y_{t-i}$. La valeur de $p$ est déterminée par $PACF_i \\approx 0$  \n",
    "- pour déterminer $q$, on utilisera l'ACF (*Auto Correlation Function*). La fonction ACF calcule la correlation entre la série temporelle et elle-même avec un décalage temporel. Soit calculer la correlation de $Y_(t, t-1, ...)$ avec $Y_(t-i, t-i-1, ...)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF & PACF plots\n",
    "from pmdarima.utils import acf, pacf\n",
    "\n",
    "n_sample = len(train)\n",
    "lag_acf = acf(np.log(train).diff().dropna(), nlags=25)\n",
    "lag_pacf = pacf(np.log(train).diff().dropna(), nlags=25)\n",
    "\n",
    "pct_95 = 1.96/np.sqrt(n_sample)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "#Plot ACF:\n",
    "plt.subplot(121)\n",
    "plt.stem(lag_acf)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-pct_95, linestyle='--', color='gray')\n",
    "plt.axhline(y=pct_95, linestyle='--', color='gray')\n",
    "# plt.axvline(x=q, color='black', linestyle='--', label=f'q={q}')\n",
    "# plt.legend()\n",
    "plt.title('Autocorrelation Function')            \n",
    "\n",
    "#Plot PACF\n",
    "plt.subplot(122)\n",
    "plt.stem(lag_pacf)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-pct_95, linestyle='--', color='gray') # represent 95 % of a gaussian data\n",
    "plt.axhline(y=pct_95, linestyle='--', color='gray') # represente 95 % of a gaussian data\n",
    "# plt.axvline(x=p, color='black', linestyle='--', label=f'p={p}')\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b59932c",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- What can you tell about the correlation for ACF and PACF?\n",
    "- Can you explain what you observe on this data (e.g. reasons for observed changes)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f67780a",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "Even this model presents a seasonality, try modeling as ARIMA(1, 1, 1)\n",
    "    </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761eb304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import ARIMA\n",
    "\n",
    "model = ARIMA(order=(12, 1, 12), suppress_warnings = True) # seasonal_order=(0, 1, 1, 12)\n",
    "model.fit(np.log(train))\n",
    "model.plot_diagnostics(figsize=(12,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe what you see on previous graphes\n",
    "# Why diagnostics functions are usefull?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.exp(prediction) to change log data back to \"Normal\"\n",
    "plt.plot(train, label='Train')\n",
    "plt.plot(test, label='Test')\n",
    "y_pred, conf_int = model.predict(n_periods=len(test), return_conf_int=True)\n",
    "plt.fill_between(y_pred.index,\n",
    "                 *np.exp(conf_int).T,\n",
    "                 alpha=0.2, color='orange',\n",
    "                 label=\"ARIMA Confidence Intervals\")\n",
    "plt.plot(np.exp(y_pred), label='ARIMA Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d405211",
   "metadata": {},
   "source": [
    "Now, find the error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#Calculate RMSE and RMSE/mean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# données connues\n",
    "plt.plot(train, label='Train')\n",
    "plt.plot(test, label='Test')\n",
    "\n",
    "# prediction\n",
    "y_pred, conf_int = model.predict(n_periods=100, return_conf_int=True)\n",
    "plt.fill_between(y_pred.index,\n",
    "                 *np.exp(conf_int).T,\n",
    "                 alpha=0.2, color='orange',\n",
    "                 label=\"ARIMA Confidence Intervals\")\n",
    "plt.plot(np.exp(y_pred), label='ARIMA Prediction')\n",
    "\n",
    "plt.title('Prediction avec ARIMA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48152ef6",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "- Yours?\n",
    "- What do you think about the error?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74d0380e",
   "metadata": {},
   "source": [
    "##### CV with ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad053f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import ARIMA\n",
    "from pmdarima.model_selection import RollingForecastCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually create the arima model\n",
    "model = ARIMA(order=(2,0,0), seasonal_order=(0, 1, 1, 12), suppress_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RollingForecastCV(h=HORIZON, step=10) # initially uses 1/3 of the training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cv need all of the training data joined together.\n",
    "airline_adj = airline / airline.index.days_in_month\n",
    "# airline_adj = np.log(airline_adj) # transform\n",
    "train, test = ts_train_test_split(airline_adj, '1960-01-01')\n",
    "train_log, test_log = np.log(train), np.log(test) # get logged values for arima model\n",
    "\n",
    "cv_results = cross_val_score(model, train_log, cv=cv, scoring=mean_absolute_percentage_error)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c884fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many splits did we get?\n",
    "len(cv_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cc8dcd7",
   "metadata": {},
   "source": [
    "**TASK**\n",
    "* go back and try different step values in the RollingForecastCV\n",
    "* What changes?\n",
    "* In each case what size is the data is the model training on?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2de4bdd7",
   "metadata": {},
   "source": [
    "##### Dealing now with seasonality: SARIMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31c8713f",
   "metadata": {},
   "source": [
    "As previously seen, ARIMA model is for stationary data. It may even works for data presenting seasonality. However, seasonality is not clearly expressed. If data shows seasonality less simple as for the airport's data, calculation complexity and time can explode.\n",
    "\n",
    "*eg:Data compiling sun activity with a seasonality of 12 +/-1 year would require a minimum of p=12*12 to comprehend seasonality of the problem.*\n",
    "\n",
    "<span style=\"color: blue\">Here comes SARIMA: Seasonal-ARIMA!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144fa1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are these parameters: (p,d,q) and (P,D,Q) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure data form\n",
    "\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def moving_std(a, n=3) :\n",
    "    j = len(a) - n\n",
    "    mov_std = np.array([np.std(a[k:k+n]) for k in range(j)])\n",
    "    return mov_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a764e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data, trend, seasonal and random infos one by one using arima.decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0fa0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_data = decomposed.seasonal + decomposed.trend\n",
    "seasonal_data = seasonal_data[~np.isnan(seasonal_data)]\n",
    "\n",
    "plt.plot(np.diff(seasonal_data, 12), label='Seasonal data, cycle 12')\n",
    "plt.plot(moving_average(seasonal_data, n=12), label='moving avg')\n",
    "plt.plot(moving_std(seasonal_data, n=12), label='moving std')\n",
    "plt.title('Seasonal data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "non_seasonal_data = decomposed.random[~np.isnan(decomposed.random)]\n",
    "plt.plot(non_seasonal_data, label='Intra seasonal data')\n",
    "plt.plot(moving_average(non_seasonal_data, n=12), label='moving avg')\n",
    "plt.plot(moving_std(non_seasonal_data, n=12), label='moving std')\n",
    "plt.title('Intra seasonal data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce0f0ad4",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- What can you conclude about stationarity of seasonal data? Can you then define D and freq?\n",
    "- Does intra-seasonal data show specific seasonality? What is d (2, 1 or 0)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0474b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quote statistical tests to define stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7002521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 12\n",
    "ocsb_diffs = nsdiffs(\n",
    "    train,\n",
    "    test='ocsb',\n",
    "    m=12, # time serie frequency\n",
    "    max_D=12 # max D for seasonality\n",
    ")\n",
    "ch_diffs = nsdiffs(train, test='ch', m=freq, max_D=12)\n",
    "n_diffs = max(ch_diffs, ocsb_diffs)\n",
    "print(f'Here seasonality for supposed frequency of {freq} is {n_diffs=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103983d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF & PACF plots\n",
    "from pmdarima.utils import acf, pacf\n",
    "\n",
    "x = np.diff(seasonal_data)\n",
    "\n",
    "n_sample = len(x)\n",
    "lag_acf = acf(x, nlags=38)\n",
    "lag_pacf = pacf(x, nlags=38)\n",
    "\n",
    "pct_95 = 1.96/np.sqrt(n_sample)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "#Plot ACF:\n",
    "plt.subplot(121)\n",
    "plt.stem(lag_acf)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-pct_95, linestyle='--', color='gray')\n",
    "plt.axhline(y=pct_95, linestyle='--', color='gray')\n",
    "plt.title('Autocorrelation Function')            \n",
    "\n",
    "#Plot PACF\n",
    "plt.subplot(122)\n",
    "plt.stem(lag_pacf)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-pct_95, linestyle='--', color='gray') \n",
    "plt.axhline(y=pct_95, linestyle='--', color='gray')\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07559df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define q and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96356462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import ARIMA\n",
    "\n",
    "model = ARIMA(\n",
    "    order=(8, 0, 4),\n",
    "    seasonal_order=(0, 1, 1, 12), # 12 for monthly data\n",
    "    suppress_warnings = True)\n",
    "model.fit(np.log(train))\n",
    "model.plot_diagnostics(figsize=(12,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# données connues\n",
    "plt.plot(train, label='Train')\n",
    "plt.plot(test, label='Test')\n",
    "\n",
    "# prediction\n",
    "y_pred, conf_int = model.predict(n_periods=100, return_conf_int=True)\n",
    "plt.fill_between(y_pred.index,\n",
    "                 *np.exp(conf_int).T,\n",
    "                 alpha=0.2, color='orange',\n",
    "                 label=\"ARIMA Confidence Intervals\")\n",
    "plt.plot(np.exp(y_pred), label='ARIMA Prediction')\n",
    "\n",
    "plt.title('Prediction avec ARIMA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c96822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE and RMSE/mean(Test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6079cd85",
   "metadata": {},
   "source": [
    "**Conclusions?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7469a18",
   "metadata": {},
   "source": [
    "##### What about Metrics?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cac07718",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/time-series-forecast-error-metrics-you-should-know-cc88b8c67f27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d3890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your comments and notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6255549d",
   "metadata": {},
   "source": [
    "#### Automatize the analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5330bae9",
   "metadata": {},
   "source": [
    "**TODO - Write a class with the following methods:**\n",
    "* The necessary arguments to split the dataset, fit the auto_arima model etc.\n",
    "* A `fit` method which fits the auto_arima naive using a train dataset\n",
    "* A `get_metrics` method which computes the MAPE for each models using a test dataset\n",
    "* A `predict` method which takes as input a prediction horizon and returns predicted values.\n",
    "* A `plot` method which plots the data, and if available the predictions \n",
    "\n",
    "**Bonus:** \n",
    "* Add a method get_cv Which performs cross validation\n",
    "* To further automatize the process add an automatic detection of the period.\n",
    "* Add the possibility to apply a preprocessing of the data before the fit: such as a log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db317926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91c6ed1a",
   "metadata": {},
   "source": [
    "**TODO - Test this method on all the other [11 datasets] of pmdarima**\n",
    "\n",
    "https://alkaline-ml.com/pmdarima/modules/classes.html#module-pmdarima.datasets\n",
    "To help you, we provide the list of dataset names and a function to load any of these datasets.\n",
    "\n",
    "On some of them the method does not work well, why? What could be done to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c706e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima\n",
    "\n",
    "dataset_names = ['airpassengers', 'ausbeer', 'austres', 'gasoline', 'heartrate', 'lynx', 'msft', 'sunspots', 'taylor', 'wineind', 'woolyrnq']\n",
    "def get_ds(ds_name, red_factor=None):\n",
    "    '''\n",
    "    Loads a dataset of pmdarima from its ds_name.\n",
    "    '''\n",
    "    ds = getattr(pmdarima.datasets, 'load_'+ds_name)(as_series=True).dropna()\n",
    "    if red_factor is not None:\n",
    "        assert isinstance(red_factor, int)\n",
    "        ds= ds.groupby(np.arange(ds.index.shape[0])//red_factor).mean()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83595d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c92419d",
   "metadata": {},
   "source": [
    "#### Want some more?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e89318ea",
   "metadata": {},
   "source": [
    "**data**: \n",
    "- choose your poison: https://data.world/datasets/time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f8ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vibration_env)",
   "language": "python",
   "name": "vibration_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
