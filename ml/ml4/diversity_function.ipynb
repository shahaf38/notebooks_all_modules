{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 12:52:26.555535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-17 12:52:26.555585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-17 12:52:26.557681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-17 12:52:26.569913: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 12:52:28.129618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-17 12:52:29.661047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 552 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:61:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 12:52:31.369706: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-17 12:52:31.939221: I external/local_xla/xla/service/service.cc:168] XLA service 0x7eec546a5680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-17 12:52:31.939267: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660, Compute Capability 7.5\n",
      "2024-05-17 12:52:31.951464: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-17 12:52:31.983407: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715943152.161632  103483 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 4s 6ms/step - loss: 12.8522 - mse: 12.8510 - val_loss: 11.4951 - val_mse: 11.4933\n",
      "Epoch 2/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 10.6658 - mse: 10.6583 - val_loss: 11.0972 - val_mse: 11.0795\n",
      "Epoch 3/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 6.8656 - mse: 6.8327 - val_loss: 10.7969 - val_mse: 10.7476\n",
      "Epoch 4/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 4.5732 - mse: 4.5101 - val_loss: 10.6678 - val_mse: 10.5924\n",
      "Epoch 5/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 3.7658 - mse: 3.6815 - val_loss: 10.6136 - val_mse: 10.5212\n",
      "Epoch 6/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 3.3694 - mse: 3.2706 - val_loss: 10.5830 - val_mse: 10.4782\n",
      "Epoch 7/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 3.1064 - mse: 2.9967 - val_loss: 10.5628 - val_mse: 10.4481\n",
      "Epoch 8/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 2.9085 - mse: 2.7898 - val_loss: 10.5496 - val_mse: 10.4270\n",
      "Epoch 9/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 2.7470 - mse: 2.6211 - val_loss: 10.5409 - val_mse: 10.4119\n",
      "Epoch 10/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 2.6083 - mse: 2.4765 - val_loss: 10.5352 - val_mse: 10.4009\n",
      "Epoch 11/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 2.4854 - mse: 2.3489 - val_loss: 10.5319 - val_mse: 10.3932\n",
      "Epoch 12/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 2.3738 - mse: 2.2333 - val_loss: 10.5301 - val_mse: 10.3879\n",
      "Epoch 13/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 2.2710 - mse: 2.1272 - val_loss: 10.5302 - val_mse: 10.3851\n",
      "Epoch 14/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 2.1755 - mse: 2.0292 - val_loss: 10.5305 - val_mse: 10.3829\n",
      "Epoch 15/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 2.0862 - mse: 1.9376 - val_loss: 10.5317 - val_mse: 10.3822\n",
      "Epoch 16/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 2.0022 - mse: 1.8519 - val_loss: 10.5341 - val_mse: 10.3830\n",
      "Epoch 17/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.9234 - mse: 1.7716 - val_loss: 10.5362 - val_mse: 10.3838\n",
      "Epoch 18/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.8491 - mse: 1.6962 - val_loss: 10.5392 - val_mse: 10.3858\n",
      "Epoch 19/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.7792 - mse: 1.6255 - val_loss: 10.5423 - val_mse: 10.3882\n",
      "Epoch 20/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.7135 - mse: 1.5590 - val_loss: 10.5451 - val_mse: 10.3903\n",
      "Epoch 21/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.6514 - mse: 1.4963 - val_loss: 10.5489 - val_mse: 10.3936\n",
      "Epoch 22/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.5933 - mse: 1.4379 - val_loss: 10.5524 - val_mse: 10.3968\n",
      "Epoch 23/500\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.5388 - mse: 1.3831 - val_loss: 10.5561 - val_mse: 10.4003\n",
      "Epoch 24/500\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.4876 - mse: 1.3315 - val_loss: 10.5603 - val_mse: 10.4042\n",
      "Epoch 25/500\n",
      "175/178 [============================>.] - ETA: 0s - loss: 1.4398 - mse: 1.2836Restoring model weights from the end of the best epoch: 15.\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.4394 - mse: 1.2832 - val_loss: 10.5636 - val_mse: 10.4073\n",
      "Epoch 25: early stopping\n",
      "297/297 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "298/298 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "Recommendations for User 1:\n",
      "Streetcar Named Desire, A (1951): 5.51\n",
      "Shawshank Redemption, The (1994): 5.45\n",
      "Hoop Dreams (1994): 5.42\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964): 5.39\n",
      "Guess Who's Coming to Dinner (1967): 5.38\n",
      "Frances (1982): 2.35\n",
      "Texas Chainsaw Massacre 2, The (1986): 2.26\n",
      "Mortuary (1983): 0.60\n",
      "Imperium (2016): 0.60\n",
      "Conan the Barbarian (2011): 0.60\n",
      "\n",
      "Recommendations for User 2:\n",
      "Schindler's List (1993): 3.41\n",
      "Streetcar Named Desire, A (1951): 3.39\n",
      "Forrest Gump (1994): 3.38\n",
      "Pulp Fiction (1994): 3.37\n",
      "Hoop Dreams (1994): 3.37\n",
      "Reservoir Dogs (1992): 3.24\n",
      "Gigantic (A Tale of Two Johns) (2002): 2.56\n",
      "Wild Strawberries (Smultronst√§llet) (1957): 2.49\n",
      "11'09\"01 - September 11 (2002): 1.85\n",
      "Cabin Boy (1994): 1.39\n",
      "\n",
      "Recommendations for User 3:\n",
      "Shawshank Redemption, The (1994): 2.62\n",
      "Streetcar Named Desire, A (1951): 2.50\n",
      "Fight Club (1999): 2.50\n",
      "Pulp Fiction (1994): 2.50\n",
      "Forrest Gump (1994): 2.49\n",
      "Happy Gilmore (1996): 1.99\n",
      "Man with the Golden Gun, The (1974): 1.99\n",
      "National Velvet (1944): 1.25\n",
      "Memories of Murder (Salinui chueok) (2003): 0.51\n",
      "Performance (1970): 0.51\n",
      "\n",
      "Recommendations for User 4:\n",
      "Shawshank Redemption, The (1994): 4.33\n",
      "Streetcar Named Desire, A (1951): 4.33\n",
      "Hoop Dreams (1994): 4.26\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964): 4.23\n",
      "Godfather, The (1972): 4.22\n",
      "Peter Pan (1953): 3.44\n",
      "Tin Men (1987): 2.51\n",
      "Monster Squad, The (1987): 2.11\n",
      "Amityville Horror, The (2005): 0.49\n",
      "Fugitive, The (1947): 0.49\n",
      "\n",
      "Recommendations for User 5:\n",
      "Forrest Gump (1994): 4.13\n",
      "Silence of the Lambs, The (1991): 4.00\n",
      "Hoop Dreams (1994): 3.94\n",
      "Star Wars: Episode IV - A New Hope (1977): 3.85\n",
      "Matrix, The (1999): 3.77\n",
      "Motorcycle Diaries, The (Diarios de motocicleta) (2004): 3.18\n",
      "Cold Mountain (2003): 2.84\n",
      "Scary Movie 4 (2006): 0.38\n",
      "This Is My Father (1998): 0.38\n",
      "Bay, The (2012): 0.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure all necessary imports are done\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load your dataset and movies dataframes\n",
    "dataset = pd.read_csv('/home/shahaf.hen@Digital-Grenoble.local/Downloads/ml-latest-small/ratings.csv')\n",
    "movies_df = pd.read_csv('/home/shahaf.hen@Digital-Grenoble.local/Downloads/ml-latest-small/movies.csv')\n",
    "\n",
    "# Prepare the data for the model\n",
    "X = [dataset[\"userId\"].to_numpy(), dataset[\"movieId\"].to_numpy()]\n",
    "y = dataset[\"rating\"].to_numpy()\n",
    "\n",
    "# Define your model creation function if it's not already defined\n",
    "def get_mf_bias_l2_reg_model(nb_users, nb_movies, k, lambda_):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Embedding, Input, Reshape, Dot, Add, Flatten\n",
    "    from keras.regularizers import l2\n",
    "\n",
    "    dim_embeddings = k\n",
    "\n",
    "    u = Input(shape=(1,), dtype='int32', name='u__user_id')\n",
    "    i = Input(shape=(1,), dtype='int32', name='i__movie_id')\n",
    "\n",
    "    p_u = Embedding(nb_users, dim_embeddings, embeddings_regularizer=l2(lambda_), name='p_u__user_embedding')(u)\n",
    "    p_u = Reshape((dim_embeddings,), name='p_u__user_embedding_reshaped')(p_u)\n",
    "\n",
    "    q_i = Embedding(nb_movies, dim_embeddings, embeddings_regularizer=l2(lambda_), name='q_i__movie_embedding')(i)\n",
    "    q_i = Reshape((dim_embeddings,), name='q_i__movie_embedding_reshaped')(q_i)\n",
    "\n",
    "    b_u = Embedding(nb_users, 1, embeddings_regularizer=l2(lambda_), name='b_u__user_bias')(u)\n",
    "    b_u = Reshape((1,), name='b_u__user_bias_reshaped')(b_u)\n",
    "\n",
    "    b_i = Embedding(nb_movies, 1, embeddings_regularizer=l2(lambda_), name='b_i__movie_bias')(i)\n",
    "    b_i = Reshape((1,), name='b_i__movie_bias_reshaped')(b_i)\n",
    "\n",
    "    r_hat = Dot(axes=1)([p_u, q_i])\n",
    "    r_hat = Add()([r_hat, b_u, b_i])\n",
    "    r_hat = Flatten()(r_hat)\n",
    "\n",
    "    model = Model(inputs=[u, i], outputs=r_hat)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Get the number of unique users and movies\n",
    "nb_users = dataset['userId'].nunique()\n",
    "nb_movies = dataset['movieId'].nunique()\n",
    "\n",
    "# Train the model\n",
    "model = get_mf_bias_l2_reg_model(nb_users, nb_movies, k=15, lambda_=2e-05)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "model.fit(X, y, epochs=500, batch_size=512, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Define the recommendation function\n",
    "def get_top10_for_users(model, user_ids, dataset, movies_df, diversity_factor=0.5):\n",
    "    recommendations = {}\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        all_movie_ids = dataset['movieId'].unique()\n",
    "        rated_movie_ids = dataset.loc[dataset['userId'] == user_id, 'movieId'].values\n",
    "        unrated_movie_ids = np.setdiff1d(all_movie_ids, rated_movie_ids)\n",
    "\n",
    "        user_unrated_pairs = pd.DataFrame({\n",
    "            'userId': np.full_like(unrated_movie_ids, user_id),\n",
    "            'movieId': unrated_movie_ids\n",
    "        })\n",
    "\n",
    "        predictions = model.predict([user_unrated_pairs['userId'], user_unrated_pairs['movieId']])\n",
    "        user_unrated_pairs['prediction'] = predictions.flatten()\n",
    "        user_unrated_pairs = pd.merge(user_unrated_pairs, movies_df, on='movieId', how='left')\n",
    "        sorted_predictions = user_unrated_pairs.sort_values(by='prediction', ascending=False)\n",
    "\n",
    "        num_top_rated = int(10 * (1 - diversity_factor))\n",
    "        num_diverse = 10 - num_top_rated\n",
    "\n",
    "        top_rated_predictions = sorted_predictions.head(num_top_rated)\n",
    "        diverse_predictions = sorted_predictions.iloc[num_top_rated:].sample(num_diverse, random_state=42)\n",
    "\n",
    "        final_recommendations = pd.concat([top_rated_predictions, diverse_predictions]).sort_values(by='prediction', ascending=False)\n",
    "        top10_predictions = final_recommendations.head(10)\n",
    "\n",
    "        ten_best_movies = top10_predictions['title'].tolist()\n",
    "        ten_best_ratings = top10_predictions['prediction'].tolist()\n",
    "\n",
    "        recommendations[user_id] = (ten_best_movies, ten_best_ratings)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "user_ids = [1, 2, 3, 4, 5]  #  user IDs\n",
    "recommendations = get_top10_for_users(model, user_ids, dataset, movies_df)\n",
    "\n",
    "for user_id, (movies, ratings) in recommendations.items():\n",
    "    print(f\"Recommendations for User {user_id}:\")\n",
    "    for movie, rating in zip(movies, ratings):\n",
    "        print(f\"{movie}: {rating:.2f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "298/298 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df, diversity_factor=0.5):\n",
    "    recommendations = {}\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        all_movie_ids = dataset['movieId'].unique()\n",
    "        rated_movie_ids = dataset.loc[dataset['userId'] == user_id, 'movieId'].values\n",
    "        unrated_movie_ids = np.setdiff1d(all_movie_ids, rated_movie_ids)\n",
    "\n",
    "        user_unrated_pairs = pd.DataFrame({\n",
    "            'userId': np.full_like(unrated_movie_ids, user_id),\n",
    "            'movieId': unrated_movie_ids\n",
    "        })\n",
    "\n",
    "        predictions = model.predict([user_unrated_pairs['userId'], user_unrated_pairs['movieId']])\n",
    "        user_unrated_pairs['prediction'] = predictions.flatten()\n",
    "        user_unrated_pairs = pd.merge(user_unrated_pairs, movies_df, on='movieId', how='left')\n",
    "        sorted_predictions = user_unrated_pairs.sort_values(by='prediction', ascending=False)\n",
    "\n",
    "        num_top_rated = int(10 * (1 - diversity_factor))\n",
    "        num_diverse = 10 - num_top_rated\n",
    "\n",
    "        top_rated_predictions = sorted_predictions.head(num_top_rated)\n",
    "        diverse_predictions = sorted_predictions.iloc[num_top_rated:].sample(num_diverse, random_state=42)\n",
    "\n",
    "        final_recommendations = pd.concat([top_rated_predictions, diverse_predictions]).sort_values(by='prediction', ascending=False)\n",
    "        top10_predictions = final_recommendations.head(10)\n",
    "\n",
    "        ten_best_movies = top10_predictions['title'].tolist()\n",
    "        ten_best_ratings = top10_predictions['prediction'].tolist()\n",
    "\n",
    "        # Get user's usual recommendations\n",
    "        user_ratings = dataset.loc[dataset['userId'] == user_id].merge(movies_df, on='movieId', how='left')\n",
    "        usual_recommendations = user_ratings.sort_values(by='rating', ascending=False).head(10)['title'].tolist()\n",
    "\n",
    "        # Calculate variety increase\n",
    "        variety_increase = len(set(ten_best_movies) - set(usual_recommendations))\n",
    "\n",
    "        recommendations[user_id] = {\n",
    "            'recommended_movies': ten_best_movies,\n",
    "            'predicted_ratings': ten_best_ratings,\n",
    "            'variety_increase': variety_increase\n",
    "        }\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "def save_recommendations_to_file(recommendations, filename_prefix='user_recommendations_'):\n",
    "    for user_id, data in recommendations.items():\n",
    "        filename = f\"{filename_prefix}{user_id}.txt\"\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(f\"Recommendations for User {user_id}:\\n\\n\")\n",
    "            for movie, rating in zip(data['recommended_movies'], data['predicted_ratings']):\n",
    "                f.write(f\"{movie}: {rating:.2f}\\n\")\n",
    "            f.write(f\"\\nVariety Increase: {data['variety_increase']}\\n\")\n",
    "\n",
    "# Example usage:\n",
    "user_ids = [1, 2, 3, 4, 5]  # Replace with actual user IDs\n",
    "recommendations = get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n",
    "\n",
    "# Save recommendations to text files\n",
    "save_recommendations_to_file(recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    get_top10_for_users_with_diversity Function:\n",
    "        This function generates movie recommendations for each user while considering diversity. It takes the following parameters:\n",
    "            model: The trained matrix factorization model.\n",
    "            user_ids: A list of user IDs for which recommendations are to be generated.\n",
    "            dataset: The dataset containing user-movie ratings.\n",
    "            movies_df: A DataFrame containing movie information, including titles.\n",
    "            diversity_factor: A parameter controlling the balance between top-rated and diverse movie recommendations.\n",
    "        For each user:\n",
    "            It finds the movies the user hasn't rated.\n",
    "            Predicts ratings for these unrated movies using the model.\n",
    "            Sorts the predictions to get the highest-rated movies.\n",
    "            Introduces diversity by selecting a portion of top-rated movies and a portion of randomly selected movies from the remaining list.\n",
    "            Calculates the variety increase, i.e., the number of recommended movies that are not in the user's usual top-rated movies.\n",
    "\n",
    "    save_recommendations_to_file Function:\n",
    "        This function saves the recommendations to text files for each user. It takes the following parameters:\n",
    "            recommendations: A dictionary containing recommendations for each user.\n",
    "            filename_prefix: A prefix to be used for the filenames of the text files containing recommendations.\n",
    "        For each user in the recommendations dictionary:\n",
    "            It creates a text file named filename_prefix + user_id.txt.\n",
    "            Writes the recommendations for that user to the text file, along with the variety increase information.\n",
    "\n",
    "    Example Usage:\n",
    "        Define a list of user IDs for which you want to generate recommendations.\n",
    "        Call the get_top10_for_users_with_diversity function with the model, user IDs, dataset, and movies DataFrame to generate recommendations.\n",
    "        Call the save_recommendations_to_file function to save the recommendations to text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "298/298 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 841 is out of bounds for axis 1 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Get top movies matrix\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m top_movies_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_movies_for_users\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecommendations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_movies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Find farthest users\u001b[39;00m\n\u001b[1;32m     48\u001b[0m farthest_pairs \u001b[38;5;241m=\u001b[39m find_farthest_users(top_movies_matrix)\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mget_top_movies_for_users\u001b[0;34m(recommendations, num_users, num_movies)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m top_movies:\n\u001b[1;32m     10\u001b[0m         movie_idx \u001b[38;5;241m=\u001b[39m movies_df\u001b[38;5;241m.\u001b[39mindex[movies_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m movie][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Corrected line\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         \u001b[43mtop_movies_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top_movies_matrix\n",
      "\u001b[0;31mIndexError\u001b[0m: index 841 is out of bounds for axis 1 with size 50"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def get_top_movies_for_users(recommendations, num_users=5, num_movies=50):\n",
    "    top_movies_matrix = np.zeros((num_users, num_movies), dtype=int)\n",
    "\n",
    "    for idx, (user_id, data) in enumerate(recommendations.items()):\n",
    "        top_movies = data['recommended_movies'][:num_movies]\n",
    "        for movie in top_movies:\n",
    "            movie_idx = movies_df.index[movies_df['title'] == movie][0]  # Corrected line\n",
    "            top_movies_matrix[idx, movie_idx] = 1\n",
    "\n",
    "    return top_movies_matrix\n",
    "\n",
    "def find_farthest_users(top_movies_matrix):\n",
    "    num_users = top_movies_matrix.shape[0]\n",
    "    distances = np.zeros((num_users, num_users))\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    for i, j in combinations(range(num_users), 2):\n",
    "        vector_i = top_movies_matrix[i]\n",
    "        vector_j = top_movies_matrix[j]\n",
    "        cosine_similarity = np.dot(vector_i, vector_j) / (np.linalg.norm(vector_i) * np.linalg.norm(vector_j))\n",
    "        distances[i, j] = cosine_similarity\n",
    "        distances[j, i] = cosine_similarity  # cosine similarity is symmetric\n",
    "\n",
    "    # Find the farthest pairs of users\n",
    "    farthest_pairs = []\n",
    "    for _ in range(5):\n",
    "        farthest_idx = np.unravel_index(np.argmax(distances), distances.shape)\n",
    "        farthest_pairs.append((farthest_idx[0], farthest_idx[1], distances[farthest_idx]))\n",
    "        distances[farthest_idx] = -1  # Mark as visited to find the next farthest pair\n",
    "\n",
    "    return farthest_pairs\n",
    "\n",
    "# Example Usage:\n",
    "num_users = 5\n",
    "num_movies = 50\n",
    "\n",
    "# Get recommendations for 5 users\n",
    "user_ids = [1, 2, 3, 4, 5]  # Replace with actual user IDs\n",
    "recommendations = get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n",
    "\n",
    "# Get top movies matrix\n",
    "top_movies_matrix = get_top_movies_for_users(recommendations, num_users, num_movies)\n",
    "\n",
    "# Find farthest users\n",
    "farthest_pairs = find_farthest_users(top_movies_matrix)\n",
    "\n",
    "# Display farthest pairs\n",
    "for idx, (user1, user2, distance) in enumerate(farthest_pairs, 1):\n",
    "    print(f\"Farthest Pair {idx}:\")\n",
    "    print(f\"User {user1+1} and User {user2+1} (Distance: {distance:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "298/298 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 841 is out of bounds for axis 1 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Get top movies matrix\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m top_movies_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_movies_for_users\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecommendations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_movies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity matrix\u001b[39;00m\n\u001b[1;32m     48\u001b[0m cosine_similarity_matrix \u001b[38;5;241m=\u001b[39m calculate_cosine_similarity_matrix(top_movies_matrix)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mget_top_movies_for_users\u001b[0;34m(recommendations, num_users, num_movies)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(movie_id) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Check if movie ID exists\u001b[39;00m\n\u001b[1;32m     13\u001b[0m             movie_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(movie_ids \u001b[38;5;241m==\u001b[39m movie_id[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Find movie index\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m             \u001b[43mtop_movies_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top_movies_matrix\n",
      "\u001b[0;31mIndexError\u001b[0m: index 841 is out of bounds for axis 1 with size 50"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def get_top_movies_for_users(recommendations, num_users=5, num_movies=50):\n",
    "    top_movies_matrix = np.zeros((num_users, num_movies), dtype=int)\n",
    "    movie_ids = movies_df['movieId'].values  # Get movie IDs from the DataFrame\n",
    "\n",
    "    for idx, (user_id, data) in enumerate(recommendations.items()):\n",
    "        top_movies = data['recommended_movies'][:num_movies]\n",
    "        for movie in top_movies:\n",
    "            movie_id = movies_df[movies_df['title'] == movie]['movieId'].values\n",
    "            if len(movie_id) > 0:  # Check if movie ID exists\n",
    "                movie_idx = np.where(movie_ids == movie_id[0])[0][0]  # Find movie index\n",
    "                top_movies_matrix[idx, movie_idx] = 1\n",
    "\n",
    "    return top_movies_matrix\n",
    "\n",
    "def calculate_cosine_similarity_matrix(matrix):\n",
    "    # Calculate cosine similarity matrix\n",
    "    cosine_similarity_matrix = np.dot(matrix, matrix.T) / (np.linalg.norm(matrix, axis=1)[:, np.newaxis] * np.linalg.norm(matrix, axis=1))\n",
    "    return cosine_similarity_matrix\n",
    "\n",
    "def find_farthest_vectors(cosine_similarity_matrix):\n",
    "    num_vectors = cosine_similarity_matrix.shape[0]\n",
    "    farthest_pairs = []\n",
    "\n",
    "    # Find the farthest pairs of vectors\n",
    "    for i, j in combinations(range(num_vectors), 2):\n",
    "        distance = 1 - cosine_similarity_matrix[i, j]  # Distance is 1 - cosine similarity\n",
    "        farthest_pairs.append((i, j, distance))\n",
    "\n",
    "    farthest_pairs.sort(key=lambda x: x[2], reverse=True)  # Sort by distance in descending order\n",
    "\n",
    "    return farthest_pairs[:5]  # Return the top 5 farthest pairs\n",
    "\n",
    "# Example Usage:\n",
    "num_users = 5\n",
    "num_movies = 50\n",
    "\n",
    "# Get recommendations for 5 users\n",
    "user_ids = [1, 2, 3, 4, 5]  # Replace with actual user IDs\n",
    "recommendations = get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n",
    "\n",
    "# Get top movies matrix\n",
    "top_movies_matrix = get_top_movies_for_users(recommendations, num_users, num_movies)\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_similarity_matrix = calculate_cosine_similarity_matrix(top_movies_matrix)\n",
    "\n",
    "# Find farthest vectors\n",
    "farthest_pairs = find_farthest_vectors(cosine_similarity_matrix)\n",
    "\n",
    "# Display farthest pairs\n",
    "for idx, (vector1, vector2, distance) in enumerate(farthest_pairs, 1):\n",
    "    print(f\"Farthest Pair {idx}:\")\n",
    "    print(f\"Vector {vector1+1} and Vector {vector2+1} (Distance: {distance:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "298/298 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "Recommended movies for User 1:\n",
      "1. Streetcar Named Desire, A (1951)\n",
      "2. Shawshank Redemption, The (1994)\n",
      "3. Hoop Dreams (1994)\n",
      "4. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
      "5. Guess Who's Coming to Dinner (1967)\n",
      "6. Frances (1982)\n",
      "7. Texas Chainsaw Massacre 2, The (1986)\n",
      "8. Mortuary (1983)\n",
      "9. Imperium (2016)\n",
      "10. Conan the Barbarian (2011)\n",
      "\n",
      "Recommended movies for User 2:\n",
      "1. Schindler's List (1993)\n",
      "2. Streetcar Named Desire, A (1951)\n",
      "3. Forrest Gump (1994)\n",
      "4. Pulp Fiction (1994)\n",
      "5. Hoop Dreams (1994)\n",
      "6. Reservoir Dogs (1992)\n",
      "7. Gigantic (A Tale of Two Johns) (2002)\n",
      "8. Wild Strawberries (Smultronst√§llet) (1957)\n",
      "9. 11'09\"01 - September 11 (2002)\n",
      "10. Cabin Boy (1994)\n",
      "\n",
      "Recommended movies for User 3:\n",
      "1. Shawshank Redemption, The (1994)\n",
      "2. Streetcar Named Desire, A (1951)\n",
      "3. Fight Club (1999)\n",
      "4. Pulp Fiction (1994)\n",
      "5. Forrest Gump (1994)\n",
      "6. Happy Gilmore (1996)\n",
      "7. Man with the Golden Gun, The (1974)\n",
      "8. National Velvet (1944)\n",
      "9. Memories of Murder (Salinui chueok) (2003)\n",
      "10. Performance (1970)\n",
      "\n",
      "Recommended movies for User 4:\n",
      "1. Shawshank Redemption, The (1994)\n",
      "2. Streetcar Named Desire, A (1951)\n",
      "3. Hoop Dreams (1994)\n",
      "4. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
      "5. Godfather, The (1972)\n",
      "6. Peter Pan (1953)\n",
      "7. Tin Men (1987)\n",
      "8. Monster Squad, The (1987)\n",
      "9. Amityville Horror, The (2005)\n",
      "10. Fugitive, The (1947)\n",
      "\n",
      "Recommended movies for User 5:\n",
      "1. Forrest Gump (1994)\n",
      "2. Silence of the Lambs, The (1991)\n",
      "3. Hoop Dreams (1994)\n",
      "4. Star Wars: Episode IV - A New Hope (1977)\n",
      "5. Matrix, The (1999)\n",
      "6. Motorcycle Diaries, The (Diarios de motocicleta) (2004)\n",
      "7. Cold Mountain (2003)\n",
      "8. Scary Movie 4 (2006)\n",
      "9. This Is My Father (1998)\n",
      "10. Bay, The (2012)\n",
      "\n",
      "Farthest Pair 1:\n",
      "Vector 1 and Vector 2 (Distance: nan)\n",
      "Farthest Pair 2:\n",
      "Vector 1 and Vector 3 (Distance: nan)\n",
      "Farthest Pair 3:\n",
      "Vector 1 and Vector 4 (Distance: nan)\n",
      "Farthest Pair 4:\n",
      "Vector 1 and Vector 5 (Distance: nan)\n",
      "Farthest Pair 5:\n",
      "Vector 2 and Vector 3 (Distance: nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103393/360308360.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  cosine_similarity_matrix = np.dot(matrix, matrix.T) / (np.linalg.norm(matrix, axis=1)[:, np.newaxis] * np.linalg.norm(matrix, axis=1))\n"
     ]
    }
   ],
   "source": [
    "def get_top_movies_for_users_with_recommendations(recommendations, movies_df, num_users=5, num_movies=50):\n",
    "    top_movies_matrix = np.zeros((num_users, num_movies), dtype=int)\n",
    "    recommended_movies = []\n",
    "\n",
    "    movie_ids = movies_df['movieId'].values  # Get movie IDs from the DataFrame\n",
    "\n",
    "    for idx, (user_id, data) in enumerate(recommendations.items()):\n",
    "        top_movies = data['recommended_movies'][:num_movies]\n",
    "        recommended_movies.append(top_movies)  # Store recommended movies for display\n",
    "        for movie in top_movies:\n",
    "            movie_id = movies_df[movies_df['title'] == movie]['movieId'].values\n",
    "            if len(movie_id) > 0:  # Check if movie ID exists\n",
    "                movie_idx = np.where(movie_ids == movie_id[0])[0][0]  # Find movie index\n",
    "                if movie_idx < num_movies:  # Ensure movie index is within bounds\n",
    "                    top_movies_matrix[idx, movie_idx] = 1\n",
    "\n",
    "    return top_movies_matrix, recommended_movies\n",
    "\n",
    "# Example Usage:\n",
    "num_users = 5\n",
    "num_movies = 50\n",
    "\n",
    "# Get recommendations for 5 users\n",
    "user_ids = [1, 2, 3, 4, 5]  # Replace with actual user IDs\n",
    "recommendations = get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n",
    "\n",
    "# Get top movies matrix and recommended movies\n",
    "top_movies_matrix, recommended_movies = get_top_movies_for_users_with_recommendations(recommendations, movies_df, num_users, num_movies)\n",
    "\n",
    "# Display recommended movies for each user\n",
    "for user_id, movies in zip(user_ids, recommended_movies):\n",
    "    print(f\"Recommended movies for User {user_id}:\")\n",
    "    for i, movie in enumerate(movies, 1):\n",
    "        print(f\"{i}. {movie}\")\n",
    "    print()\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_similarity_matrix = calculate_cosine_similarity_matrix(top_movies_matrix)\n",
    "\n",
    "# Find farthest vectors\n",
    "farthest_pairs = find_farthest_vectors(cosine_similarity_matrix)\n",
    "\n",
    "# Display farthest pairs\n",
    "for idx, (vector1, vector2, distance) in enumerate(farthest_pairs, 1):\n",
    "    print(f\"Farthest Pair {idx}:\")\n",
    "    print(f\"Vector {vector1+1} and Vector {vector2+1} (Distance: {distance:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Generate Recommendations: We use the trained model to generate recommendations for each user. These recommendations are typically sorted by predicted ratings in descending order.\n",
    "\n",
    "    Extract Top Movies: From the generated recommendations, we extract the top 50 movies for each user. These are the movies that are most highly rated by the model for that user.\n",
    "\n",
    "    Prepare Binary Matrix: We prepare a binary matrix where each row represents a user's recommended movies. Each column corresponds to a movie, and a value of 1 indicates that the movie is recommended for that user, while 0 indicates it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "298/298 [==============================] - 1s 2ms/step\n",
      "303/303 [==============================] - 1s 2ms/step\n",
      "Recommended movies have been written to recommended_movies.txt.\n"
     ]
    }
   ],
   "source": [
    "def write_recommendations_to_file(file_path, user_ids, recommended_movies):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for user_id, movies in zip(user_ids, recommended_movies):\n",
    "            f.write(f\"Recommended movies for User {user_id}:\\n\")\n",
    "            for i, movie in enumerate(movies, 1):\n",
    "                f.write(f\"{i}. {movie}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Example Usage:\n",
    "num_users = 5\n",
    "num_movies = 50\n",
    "file_path = \"recommended_movies.txt\"  # Path to the output text file\n",
    "\n",
    "# Get recommendations for 5 users\n",
    "user_ids = [1, 2, 3, 4, 5]  # Replace with actual user IDs\n",
    "recommendations = get_top10_for_users_with_diversity(model, user_ids, dataset, movies_df)\n",
    "\n",
    "# Get top movies matrix and recommended movies\n",
    "top_movies_matrix, recommended_movies = get_top_movies_for_users_with_recommendations(recommendations, movies_df, num_users, num_movies)\n",
    "\n",
    "# Write recommended movies to file\n",
    "write_recommendations_to_file(file_path, user_ids, recommended_movies)\n",
    "\n",
    "print(f\"Recommended movies have been written to {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the distance between vectors in the cosine similarity matrix, we can use the cosine similarity itself as a measure of similarity. Cosine similarity measures the cosine of the angle between two vectors and ranges from -1 to 1.\n",
    "\n",
    "The cosine similarity similarity(A,B)similarity(A,B) between two vectors AA and BB is defined as:\n",
    "similarity(A,B)=A‚ãÖB‚à•A‚à•‚à•B‚à•\n",
    "similarity(A,B)=‚à•A‚à•‚à•B‚à•A‚ãÖB‚Äã\n",
    "\n",
    "Where A‚ãÖBA‚ãÖB is the dot product of vectors AA and BB, and ‚à•A‚à•‚à•A‚à• and ‚à•B‚à•‚à•B‚à• are the magnitudes of vectors AA and BB respectively.\n",
    "\n",
    "To convert the cosine similarity to a distance measure, we subtract it from 1. This is because cosine similarity of 1 means the vectors are perfectly aligned (have no angle between them), and cosine similarity of -1 means they are perfectly anti-aligned. So, subtracting from 1 gives us a value where higher values mean vectors are more similar (closer) and lower values mean they are more dissimilar (farther).\n",
    "\n",
    "Therefore, the distance distance(A,B)distance(A,B) between two vectors AA and BB is defined as:\n",
    "distance(A,B)=1‚àísimilarity(A,B)\n",
    "distance(A,B)=1‚àísimilarity(A,B)\n",
    "\n",
    "We can use this formula to calculate the distance between vectors in the cosine similarity matrix. The greater the distance, the more dissimilar the vectors are, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
